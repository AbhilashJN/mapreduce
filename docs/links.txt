https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exe_local
https://docs.nvidia.com/cuda/cuda-c-programming-guide/contents.html
https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY__POOLS.html
https://www.olcf.ornl.gov/cuda-training-series/
https://forums.developer.nvidia.com/t/confusion-about-synchronization-or-asynchronization-of-cudamemcpy-and-cudamemcpyasync/276826/4
https://pytorch.org/tutorials/intermediate/pinmem_nonblock.html


Windows:

wsl -d Ubuntu

Need WSL for running a container for Nvidia container toolkit for using GPUs through a container on the host.
https://learn.microsoft.com/en-us/windows/wsl/setup/environment
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html

Once installed, check that it is working.
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi

docker build -t cuda .
docker run --gpus all -it --rm -v $(pwd)/app:/app cuda bash
